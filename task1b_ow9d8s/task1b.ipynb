{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IML 18 - Project\n",
    "## Task 1b: Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-11T11:57:46.052002Z",
     "start_time": "2018-03-11T11:57:46.006900Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.base import clone\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-11T11:57:47.872478Z",
     "start_time": "2018-03-11T11:57:47.860200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load training data CSV using Pandas\n",
    "filename = 'train.csv'\n",
    "data = pd.read_csv(filename, header=0)\n",
    "# Separate training data into Y and X\n",
    "array = data.values\n",
    "Y = array[:, 1]\n",
    "X = array[:, 2:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-11T11:57:49.272859Z",
     "start_time": "2018-03-11T11:57:49.266610Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split data into own train and test sets\n",
    "test_size = 0.1\n",
    "seed = 13\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,\n",
    "                                                    test_size=test_size,\n",
    "                                                    random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-11T11:57:52.420755Z",
     "start_time": "2018-03-11T11:57:52.405587Z"
    }
   },
   "outputs": [],
   "source": [
    "# define feature transformation as given by task description\n",
    "def feature_transform(X):\n",
    "    x1, x2, x3, x4, x5 = X[:,0], X[:,1], X[:,2], X[:,3], X[:,4] \n",
    "    return np.column_stack((\n",
    "                     x1,\n",
    "                     x2,\n",
    "                     x3,\n",
    "                     x4,\n",
    "                     x5,\n",
    "                     x1**2,\n",
    "                     x2**2,\n",
    "                     x3**2,\n",
    "                     x4**2,\n",
    "                     x5**2,\n",
    "                     np.exp(x1),\n",
    "                     np.exp(x2),\n",
    "                     np.exp(x3),\n",
    "                     np.exp(x4),\n",
    "                     np.exp(x5),\n",
    "                     np.cos(x1),\n",
    "                     np.cos(x2),\n",
    "                     np.cos(x3),\n",
    "                     np.cos(x4),\n",
    "                     np.cos(x5),\n",
    "                     np.ones_like(x1)\n",
    "                     ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-11T11:58:08.352720Z",
     "start_time": "2018-03-11T11:58:08.347967Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make pipeline: mandatory transformations plus other experiments\n",
    "pipeline = Pipeline([\n",
    "#     ('std_scaler', StandardScaler()), # can't use as test set not handed out\n",
    "     ('feature_transformer', FunctionTransformer(feature_transform)),\n",
    "#     ('PCA', PCA()) # can't use as test set not handed out\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-11T11:58:09.401032Z",
     "start_time": "2018-03-11T11:58:09.394377Z"
    }
   },
   "outputs": [],
   "source": [
    "# Transform train and test sets with pipeline\n",
    "X_train_prepared = pipeline.fit_transform(X_train)\n",
    "X_test_prepared = pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-11T11:58:14.744210Z",
     "start_time": "2018-03-11T11:58:14.692218Z"
    }
   },
   "outputs": [],
   "source": [
    "# Experiment: Test across a wide selection of models to get a feel for the data\n",
    "# Create list of models to be tested\n",
    "models = []\n",
    "# LinearRegressor for baseline\n",
    "models.append(('linear_reg',\n",
    "              LinearRegression(),\n",
    "              {}\n",
    "              ))\n",
    "# # XGBRegressor for feature selection\n",
    "# models.append(('xgboost_reg',\n",
    "#              XGBRegressor(subsample = 0.5,\n",
    "#              objective = 'reg:linear',\n",
    "#              num_estimators = 1000,\n",
    "#              learning_rate = 0.2),\n",
    "#              [{'max_depth': [5, 10, 20, 30],\n",
    "#                'min_child_weight': [1, 3, 5, 8, 10],\n",
    "#                'colsample_bytree': [0.6, 0.8, 1.0]}]\n",
    "#              ))\n",
    "# # RandomForestRegressor for feature selection\n",
    "# models.append(('forest_reg',\n",
    "#               RandomForestRegressor(random_state=42),\n",
    "#               [{'bootstrap': [True, False],\n",
    "#               'n_estimators': [10, 20, 40],\n",
    "#               'max_features': [2, 4, 8, 16, 21]}]\n",
    "#               ))\n",
    "# # ExtraTreesRegressor for feature selection\n",
    "# models.append(('extraTrees_reg',\n",
    "#               ExtraTreesRegressor(n_estimators=50, max_features=0.5,\n",
    "#                                   bootstrap=True, oob_score=True,\n",
    "#                                   n_jobs=-1, random_state=42),\n",
    "#               {}\n",
    "#               ))\n",
    "\n",
    "# models.append(('lasso_reg',\n",
    "#               Lasso(max_iter=1e6, tol=1e-5, random_state=42),\n",
    "#               {}\n",
    "#               ))\n",
    "    \n",
    "models.append(('elastic_net',\n",
    "              ElasticNet(max_iter=1e6, tol=1e-4,\n",
    "                         random_state=42, selection='random'),\n",
    "              [{'alpha': [1.0],\n",
    "              'l1_ratio': [0.4, 0.8, 1.0]}]\n",
    "              ))\n",
    "        \n",
    "# models.append(('svm_reg',\n",
    "#               SVR(max_iter=-1, tol=1e-5, verbose=0),\n",
    "#               [{'C': [0.1, 1, 10],\n",
    "#               'epsilon': [0.1, 0.3, 0.5],\n",
    "#               'kernel': ['linear', 'poly', 'rbf', 'sigmoid']}]\n",
    "#               ))\n",
    "\n",
    "# models.append(('sgd_reg',\n",
    "#               SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=5e-4,\n",
    "#               fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
    "#               loss='huber', max_iter=1e4, n_iter=None, penalty='elasticnet',\n",
    "#               power_t=0.25, random_state=None, shuffle=True, tol=1e-3,\n",
    "#               verbose=0, warm_start=True),\n",
    "#               {}\n",
    "#               ))\n",
    "\n",
    "# models.append(('linear_svm',\n",
    "#               LinearSVR(dual=True, fit_intercept=True,\n",
    "#                         intercept_scaling=1.0, max_iter=1e6,\n",
    "#                         random_state=42, tol=1e-5, verbose=0),\n",
    "#               [{'C': [10],\n",
    "#               'loss': ['epsilon_insensitive','squared_epsilon_insensitive'],\n",
    "#               'epsilon': [0.9, 1.8, 3.6]}]\n",
    "#               ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-11T11:58:17.052149Z",
     "start_time": "2018-03-11T11:58:16.099976Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "linear_reg RMSE: 10.9\n",
      "............................................................\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elastic_net RMSE: 11.9\n",
      "............................................................\n",
      "Overall ranking\n",
      "Estimator: \t RMSE:\n",
      "----------------------\n",
      "linear_reg \t 10.9\n",
      "elastic_net \t 11.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "# From above: Collect models' results of grid search with cross validation\n",
    "results = {}\n",
    "for (name, model, param_grid) in models:\n",
    "    grid_search = GridSearchCV(model,\n",
    "                           param_grid, n_jobs=-1, cv=5,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           verbose=1, return_train_score=True)\n",
    "    grid_search.fit(X_train_prepared, Y_train)\n",
    "    pred = grid_search.best_estimator_.predict(X_test_prepared)\n",
    "    rmse = np.sqrt(mean_squared_error(Y_test, pred))\n",
    "    print('{0} RMSE: {1:.3}'.format(name, rmse))\n",
    "    results[name] = [grid_search.best_estimator_, rmse]\n",
    "    print(60*'.')\n",
    "\n",
    "print(\"Overall ranking\")\n",
    "print(\"Estimator: \\t RMSE:\")\n",
    "print(22*'-')\n",
    "for (name, value) in sorted(results.items(), key=lambda x:x[1][1]):\n",
    "    print('{0} \\t {1:.3}'.format(name, value[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-11T10:29:29.444195Z",
     "start_time": "2018-03-11T10:29:29.420812Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(810, 10)\n",
      "(90, 10)\n"
     ]
    }
   ],
   "source": [
    "# Experiment: Automatic feature selection by XGBoost\n",
    "feature_select = SelectFromModel(results['xgboost_reg'][0], prefit=True)\n",
    "X_train_new = feature_select.transform(X_train_prepared)\n",
    "X_test_new = feature_select.transform(X_test_prepared)\n",
    "print(X_train_new.shape)\n",
    "print(X_test_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-11T11:58:44.022612Z",
     "start_time": "2018-03-11T11:58:39.713012Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 10.9\n",
      "[-0.66947449  3.09220664 -2.75039943  6.48302226 -3.25570265 -0.59670293\n",
      "  0.23511655  0.          1.01601232 -0.          0.0932698  -3.53037198\n",
      "  0.16434826 -0.05712628  0.01665568  0.         -0.          0.\n",
      " -0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Experiment: ElasticNetCV to estimate ElasticNet base performance\n",
    "elastic_cv = ElasticNetCV(\n",
    "                          cv=5,\n",
    "                          eps=0.001,\n",
    "                          fit_intercept=True,\n",
    "                          l1_ratio=[.1, .5, .7, .9, .95, .99, 1],\n",
    "                          max_iter=1e6,\n",
    "                          n_alphas=1000,\n",
    "                          n_jobs=-1,\n",
    "                          normalize=False,\n",
    "                          precompute='auto',\n",
    "                          random_state=42,\n",
    "                          selection='cyclic',\n",
    "                          tol=1e-4,\n",
    "                          verbose=0)\n",
    "elastic_cv.fit(X_train_prepared, Y_train)\n",
    "pred = elastic_cv.predict(X_test_prepared)\n",
    "rmse = np.sqrt(mean_squared_error(Y_test, pred))\n",
    "print('RMSE: {0:.3}'.format(rmse))\n",
    "print(elastic_cv.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-11T12:03:58.860799Z",
     "start_time": "2018-03-11T12:02:25.915021Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator 0 RMSE: 11.0\n",
      "Estimator 1 RMSE: 10.9\n",
      "Estimator 2 RMSE: 11.0\n",
      "Estimator 3 RMSE: 11.0\n",
      "Estimator 4 RMSE: 11.0\n",
      "Estimator 5 RMSE: 10.9\n",
      "Estimator 6 RMSE: 11.1\n",
      "Estimator 7 RMSE: 10.9\n",
      "Estimator 8 RMSE: 11.1\n",
      "Estimator 9 RMSE: 11.1\n",
      "Estimator 10 RMSE: 11.0\n",
      "Estimator 11 RMSE: 11.0\n",
      "Estimator 12 RMSE: 11.1\n",
      "Estimator 13 RMSE: 11.1\n",
      "Estimator 14 RMSE: 10.9\n",
      "Estimator 15 RMSE: 11.0\n",
      "Estimator 16 RMSE: 10.9\n",
      "Estimator 17 RMSE: 11.0\n",
      "Estimator 18 RMSE: 11.1\n",
      "Estimator 19 RMSE: 10.9\n",
      "Bag of 20 estimators RMSE: 12.6\n"
     ]
    }
   ],
   "source": [
    "# Chosen approach: A manually constructed bag of ElasticNetCVs\n",
    "w_coeff = np.zeros(X_train_prepared.shape[1], dtype='float64')\n",
    "n_estimators = 20\n",
    "sample_ratio = 0.9\n",
    "n_samples = X_train_prepared.shape[0]\n",
    "batch_size = int(sample_ratio * n_samples)\n",
    "for i in range(n_estimators):\n",
    "    sample_rows = np.random.choice(X_train_prepared.shape[0],\n",
    "                               batch_size, replace=False)\n",
    "    batch_X_train_prepared = X_train_prepared[sample_rows, :]\n",
    "    batch_Y_train = Y_train[sample_rows]\n",
    "    elastic_cv = ElasticNetCV(\n",
    "                          cv=5,\n",
    "                          eps=0.001,\n",
    "                          fit_intercept=True,\n",
    "                          l1_ratio=[.1, .5, .7, .9, .95, .99, 1],\n",
    "                          max_iter=1e6,\n",
    "                          n_alphas=1000,\n",
    "                          n_jobs=-1,\n",
    "                          normalize=False,\n",
    "                          precompute='auto',\n",
    "                          random_state=42,\n",
    "                          selection='cyclic',\n",
    "                          tol=1e-4,\n",
    "                          verbose=0)\n",
    "    elastic_cv.fit(batch_X_train_prepared, batch_Y_train)\n",
    "    pred = elastic_cv.predict(X_test_prepared)\n",
    "    rmse = np.sqrt(mean_squared_error(Y_test, pred))\n",
    "    print('Estimator {0} RMSE: {1:.3}'.format(i, rmse))\n",
    "    w_coeff += elastic_cv.coef_\n",
    "w_coeff /= n_estimators\n",
    "\n",
    "error=0\n",
    "for i in range(X_test_prepared.shape[0]):\n",
    "    error += (w.dot(X_test_prepared[i])-Y_test[i])**2\n",
    "rmse=np.sqrt(error/n)\n",
    "print('Bag of {0} estimators RMSE: {1:.3}'.format(n_estimators, rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-11T12:01:50.622681Z",
     "start_time": "2018-03-11T12:01:26.349838Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 11.0, OOB score: 0.827\n"
     ]
    }
   ],
   "source": [
    "# Experiment: BaggingRegressor on ElasticNetCV to get OOB score\n",
    "elastic_bagging = BaggingRegressor(base_estimator=ElasticNetCV(cv=5,\n",
    "                                          eps=0.001,\n",
    "                                          fit_intercept=True,\n",
    "                                          l1_ratio=[.1, .5, .7, .9, .95, .99, 1],\n",
    "                                          max_iter=1e6,\n",
    "                                          n_alphas=1000,\n",
    "                                          n_jobs=-1,\n",
    "                                          normalize=False,\n",
    "                                          precompute='auto',\n",
    "                                          random_state=42,\n",
    "                                          selection='cyclic',\n",
    "                                          tol=1e-4,\n",
    "                                          verbose=0),\n",
    "                                  n_estimators=20,\n",
    "                                  max_samples=0.9,\n",
    "                                  max_features=0.9,\n",
    "                                  bootstrap=True,\n",
    "                                  bootstrap_features=False,\n",
    "                                  oob_score=True,\n",
    "                                  warm_start=False,\n",
    "                                  n_jobs=-1,\n",
    "                                  random_state=42,\n",
    "                                  verbose=0)\n",
    "elastic_bagging.fit(X_train_prepared, Y_train)\n",
    "pred = elastic_bagging.predict(X_test_prepared)\n",
    "rmse = np.sqrt(mean_squared_error(Y_test, pred))\n",
    "oob = elastic_bagging.oob_score_\n",
    "print('RMSE: {0:.3}, OOB score: {1:.3}'.format(rmse, oob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-11T12:06:06.090457Z",
     "start_time": "2018-03-11T12:06:06.072762Z"
    }
   },
   "outputs": [],
   "source": [
    "# Decide on final model and write to file\n",
    "# final_model = None\n",
    "result = w_coeff\n",
    "# final_pred = final_model.predict(X_test_prepared)\n",
    "# final_rmse = np.sqrt(mean_squared_error(Y_test, final_pred))\n",
    "# print(\"Final RMSE: {:.3}\".format(final_rmse))\n",
    "filename = 'result.csv'\n",
    "final_result = pd.DataFrame(result)\n",
    "final_result.to_csv(filename, header=False, index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
